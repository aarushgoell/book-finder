ğŸ“š Book Finder â€“ AI-Powered Book Recommendation App

A full-stack web application that recommends books based on user prompts using an AI/LLM backend. Users can input a theme or idea (e.g., "space adventure", "romantic classics"), and the app responds with 5 personalized book suggestions, including title, summary, and genre.

ğŸš€ Features

âœ… User enters any topic or keyword prompt

âœ… Flask backend calls a mocked or LLM-powered function

âœ… JSON response with 5 recommended books

âœ… React frontend displays the books in a clean, responsive UI

âœ… Ready to plug in with OpenAI, Hugging Face, or any LLM API

ğŸ§  Tech Stack

Frontend

React + Vite

Axios for HTTP requests

Tailwind CSS (optional) for UI styling

Backend

Python + Flask

CORS enabled for frontend-backend integration

Mocked LLM response or real LLM integration (OpenAI / Hugging Face)

ğŸ“ Folder Structure

/book-finder
â”œâ”€â”€ backend
â”‚   â”œâ”€â”€ app.py                 # Flask API with /api/books endpoint
â”‚   â”œâ”€â”€ open_Api.py            # Contains get_book_recommendations(prompt)
â”‚   â””â”€â”€ requirements.txt

â”œâ”€â”€ frontend
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ App.jsx            # Main app component
â”‚   â”‚   â”œâ”€â”€ BookForm.jsx       # Input field and Search button
â”‚   â”‚   â”œâ”€â”€ BookList.jsx       # Displays books as cards
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â””â”€â”€ vite.config.js

âš™ï¸ How to Run the App

1. Clone the Repository

git clone https://github.com/aarushgoel/book-finder.git
cd book-finder

2. Backend Setup

cd backend
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate (Windows)
pip install -r requirements.txt
python app.py

Server runs at http://localhost:5000

3. Frontend Setup

cd frontend
npm install
npm run dev

Frontend runs at http://localhost:5173

ğŸ§ª Example Prompt & Output

Prompt: fantasy books with dragons and magic

Response:

[
  {
    "title": "Eragon",
    "summary": "A farm boy discovers a dragon egg that changes his destiny.",
    "genre": "Fantasy"
  },
  {
    "title": "The Hobbit",
    "summary": "Bilbo Baggins goes on a quest to reclaim treasure from a dragon.",
    "genre": "Fantasy"
  }
  ... 3 more
]

ğŸ“ Notes

If using a mocked LLM, make sure mistral_utils.py returns a JSON-formatted string.

You can replace the mocked function with a real OpenAI or Hugging Face API call.

CORS must be enabled in Flask if frontend and backend are running separately.

Environment variables should store API keys securely if deployed.

ğŸŒ Deployment Tips

Backend (Render)

Create a new web service

Set build command to: pip install -r requirements.txt

Start command: python app.py

Add cors and flask to requirements.txt

Frontend (Vercel or Netlify)

Just drag & drop the frontend folder or connect GitHub repo

Set base API URL to backend deployment URL

ğŸ¥ Submission Checklist



ğŸ™Œ Author

Aarush GoelFull Stack Developer â€¢ React â€¢ Flask â€¢ OpenAI IntegrationGitHub | LinkedIn

